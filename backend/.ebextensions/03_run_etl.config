# Run ETL after deployment
# Note: Tables are created in app/main.py on startup, so we don't need to create them here
# The ETL will run after the app starts, or we can run it manually
files:
  "/opt/elasticbeanstalk/hooks/appdeploy/post/99_run_etl.sh":
    mode: "000755"
    owner: root
    group: root
    content: |
      #!/bin/bash
      set +e  # Don't exit on error - let ETL run even if there are minor issues
      cd /var/app/current
      
      # Ensure database file exists and has correct permissions
      touch /var/app/current/nyc_taxi.db
      chown webapp:webapp /var/app/current/nyc_taxi.db
      chmod 664 /var/app/current/nyc_taxi.db
      
      export PYTHONPATH="/var/app/current:$PYTHONPATH"
      
      # Find Python in venv (venv name changes, so we search for it)
      VENV_DIR=$(ls -d /var/app/venv/staging-* 2>/dev/null | head -1)
      if [ -n "$VENV_DIR" ] && [ -f "$VENV_DIR/bin/python" ]; then
        PYTHON="$VENV_DIR/bin/python"
      else
        PYTHON=python3
      fi
      
      echo "=========================================="
      echo "ETL Deployment Hook Started"
      echo "=========================================="
      echo "Python: $PYTHON"
      echo "Data directory: /var/app/current/data"
      echo "Database: /var/app/current/nyc_taxi.db"
      
      # Check if data directory exists
      if [ ! -d "/var/app/current/data" ]; then
        echo "ERROR: Data directory not found at /var/app/current/data"
        echo "ETL will not run. Please check data download configuration."
        exit 0  # Don't fail deployment
      fi
      
      # List data files
      echo "Data files found:"
      ls -lh /var/app/current/data/ || echo "Warning: Could not list data files"
      
      # Check if ETL is already running
      if pgrep -f "run_etl.py" > /dev/null; then
        echo "ETL process already running, skipping..."
        exit 0
      fi
      
      # Check if optimized database was downloaded from S3 (skip ETL if database exists)
      if [ -f "/var/app/current/nyc_taxi.db" ]; then
        DB_SIZE=$(stat -f%z /var/app/current/nyc_taxi.db 2>/dev/null || stat -c%s /var/app/current/nyc_taxi.db 2>/dev/null || echo "0")
        DB_SIZE_MB=$((DB_SIZE / 1024 / 1024))
        
        if [ "$DB_SIZE" -gt 1000000 ]; then  # If DB > 1MB, assume data exists
          echo "=========================================="
          echo "Optimized database found (${DB_SIZE_MB} MB)"
          echo "Skipping ETL - using pre-built database from S3"
          echo "=========================================="
          echo "Database file: /var/app/current/nyc_taxi.db"
          echo "This database contains optimized January data with indexes"
          echo "To re-run ETL, delete the database file first"
          echo "=========================================="
          exit 0
        else
          echo "Database file exists but is too small (${DB_SIZE} bytes). Will run ETL."
        fi
      else
        echo "No database file found. Will run ETL to create database."
      fi
      
      echo "Starting ETL process in background..."
      # Run ETL with correct data path using run_etl.py script
      # Run in background so deployment doesn't wait
      # Use timeout to prevent hanging (25 minutes max)
      nohup timeout 1500 $PYTHON run_etl.py --data-dir ./data > /var/app/current/etl.log 2>&1 &
      ETL_PID=$!
      
      echo "ETL started in background (PID: $ETL_PID)"
      echo "Log file: /var/app/current/etl.log"
      echo "ETL will continue running even after deployment completes"
      echo "This may take 15-30 minutes on t3.medium instance"
      echo "Monitor progress: tail -f /var/app/current/etl.log"
      echo "=========================================="
      
      # Give it a moment to start
      sleep 2
      
      # Verify it's still running
      if ps -p $ETL_PID > /dev/null 2>&1; then
        echo "ETL process confirmed running"
      else
        echo "WARNING: ETL process may have failed to start. Check /var/app/current/etl.log"
      fi

